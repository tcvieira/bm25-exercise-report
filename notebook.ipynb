{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TrZcrjFsym8G"
      },
      "source": [
        "# Building a Simple Information Retrieval System using BM25 and GPT-3 and evaluated in the CISI collection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/tcvieira/bm25-exercise-report/blob/main/notebook.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16Smym6lCy45"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "98Cpltx0CxIr"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import random\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umBornMxBEsv"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmrzX_JuR_0u",
        "outputId": "8588ff64-962d-4cf3-e440-4685284ab272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-02-21 18:54:04--  https://ir.dcs.gla.ac.uk/resources/test_collections/cisi/cisi.tar.gz\n",
            "Resolving ir.dcs.gla.ac.uk (ir.dcs.gla.ac.uk)... 130.209.240.253\n",
            "Connecting to ir.dcs.gla.ac.uk (ir.dcs.gla.ac.uk)|130.209.240.253|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 775144 (757K) [application/gzip]\n",
            "Saving to: ‘content/cisi.tar.gz’\n",
            "\n",
            "cisi.tar.gz         100%[===================>] 756,98K   609KB/s    in 1,2s    \n",
            "\n",
            "2023-02-21 18:54:07 (609 KB/s) - ‘content/cisi.tar.gz’ saved [775144/775144]\n",
            "\n",
            "x CISI.ALL\n",
            "x CISI.BLN\n",
            "x CISI.QRY\n",
            "x CISI.REL\n"
          ]
        }
      ],
      "source": [
        "## Download dataset\n",
        "\n",
        "!wget https://ir.dcs.gla.ac.uk/resources/test_collections/cisi/cisi.tar.gz -P content/\n",
        "!tar -xzvf 'content/cisi.tar.gz' -C content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I8mcFF_5BHId"
      },
      "outputs": [],
      "source": [
        "### Processing DOCUMENTS\n",
        "doc_set = {}\n",
        "doc_id = \"\"\n",
        "doc_text = \"\"\n",
        "with open('content/CISI.ALL') as f:\n",
        "    lines = \"\"\n",
        "    for l in f.readlines():\n",
        "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
        "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
        "doc_count = 0\n",
        "for l in lines:\n",
        "    if l.startswith(\".I\"):\n",
        "        doc_id = int(l.split(\" \")[1].strip())-1\n",
        "    elif l.startswith(\".X\"):\n",
        "        doc_set[doc_id] = doc_text.lstrip(\" \")\n",
        "        doc_id = \"\"\n",
        "        doc_text = \"\"\n",
        "    else:\n",
        "        doc_text += l.strip()[3:] + \" \" # The first 3 characters of a line can be ignored.    \n",
        "\n",
        "        \n",
        "### Processing QUERIES\n",
        "with open('content/CISI.QRY') as f:\n",
        "    lines = \"\"\n",
        "    for l in f.readlines():\n",
        "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
        "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
        "    \n",
        "qry_set = {}\n",
        "qry_id = \"\"\n",
        "for l in lines:\n",
        "    if l.startswith(\".I\"):\n",
        "        qry_id = int(l.split(\" \")[1].strip()) -1\n",
        "    elif l.startswith(\".W\"):\n",
        "        qry_set[qry_id] = l.strip()[3:]\n",
        "        qry_id = \"\"\n",
        "\n",
        "### Processing QRELS\n",
        "rel_set = {}\n",
        "with open('content/CISI.REL') as f:\n",
        "    for l in f.readlines():\n",
        "        qry_id = int(l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0]) -1\n",
        "        doc_id = int(l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1])-1\n",
        "        if qry_id in rel_set:\n",
        "            rel_set[qry_id].append(doc_id)\n",
        "        else:\n",
        "            rel_set[qry_id] = []\n",
        "            rel_set[qry_id].append(doc_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaRX9XcpFc2q"
      },
      "source": [
        "## Simple dataset EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co-_EtgvCV4o",
        "outputId": "95c60ef8-d91c-4e42-8a61-f0b91e93a3de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1460 documents\n",
            "112 queries\n",
            "76 mappings ground truth\n",
            "Average of 40.97 documents per query\n",
            "minimum of 1 relevant documents per query\n",
            "There are 36 queries without relevant documents: [ 35  37  39  46  47  50  52  58  59  62  63  67  69  71  72  73  74  76\n",
            "  77  79  82  84  85  86  87  88  90  92  93 102 104 105 106 107 109 111]\n"
          ]
        }
      ],
      "source": [
        "print(f'{len(doc_set)} documents')\n",
        "print(f'{len(qry_set)} queries') \n",
        "print(f'{len(rel_set)} mappings ground truth')\n",
        "\n",
        "number_rel_docs = [len(value) for key, value in rel_set.items()]\n",
        "print(f'Average of {np.mean(number_rel_docs):.2f} documents per query')\n",
        "print(f'minimum of {np.min(number_rel_docs)} relevant documents per query')\n",
        "\n",
        "qry_no_docs = np.setdiff1d(list(qry_set.keys()),list(rel_set.keys()))\n",
        "print(f'There are {len(qry_no_docs)} queries without relevant documents: {qry_no_docs}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCVmmEwRGpaP"
      },
      "source": [
        "Some pairs of query and relevant documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAHyQs7cGla-",
        "outputId": "1d47b49d-bbef-46cb-eedc-f2048d3f3b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query ID 14: How much do information retrieval and dissemination systems, as well as automated libraries, cost? Are they worth it to the researcher and to industry?\n",
            "\n",
            "Documents relevants to Query ID 14: [17, 26, 35, 48, 55, 58, 66, 73, 82, 125, 157, 163, 166, 191, 213, 221, 222, 249, 280, 291, 294, 298, 306, 330, 335, 337, 347, 364, 365, 366, 367, 371, 380, 445, 457, 464, 465, 481, 489, 490, 494, 496, 506, 519, 527, 590, 593, 622, 628, 638, 689, 719, 722, 723, 726, 727, 730, 778, 821, 833, 838, 847, 848, 864, 871, 896, 1099, 1160, 1247, 1304, 1352, 1357, 1362, 1365, 1367, 1370, 1371, 1373, 1374, 1375, 1376, 1409]\n",
            "\n",
            "Document ID 48: Adaptive Information Dissemination Sage, C.R. Anderson, R.R. Fitzwater, D.R. Computer dissemination of information offers significant advantages over manual dissemination because the computer can use strategies that are impractical and in some cases impossible for a human.. This paper describes the Ames Laboratory Selective Dissemination of Information system with emphasis on the effectiveness of user feedback.. The system will accept any document, abstract, keyword, etc., in a KWIC or Science Citation Index Source format.. User profiles consist of words or word clusters each with an initially assigned significance value.. These values are used in making the decision to notify a user that he may be interested in a particular document.. According to responses, the significance values are increased or decreased and quickly attain an equilibrium which accurately describes the user's interests.. The system is economical compared to other existing SDI systems and human intervention is negligible except for adding and deleting profile entries.. \n"
          ]
        }
      ],
      "source": [
        "random.seed(42)\n",
        "idx = random.sample(list(rel_set.keys()),1)[0]\n",
        "\n",
        "print(f'Query ID {idx}: {qry_set[idx]}')\n",
        "print()\n",
        "\n",
        "rel_docs = rel_set[idx]\n",
        "print(f'Documents relevants to Query ID {idx}: {rel_docs}')\n",
        "print()\n",
        "\n",
        "sample_document_idx = random.sample(rel_docs,1)[0]\n",
        "print(f'Document ID {sample_document_idx}: {doc_set[sample_document_idx]}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (3.8.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from nltk) (4.61.1)\n",
            "Requirement already satisfied: joblib in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from nltk) (8.1.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/tcvieira/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/tcvieira/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "stop_words = nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_string(txt, remove_stop=True, do_stem=True, to_lower=True):\n",
        "    \"\"\"\n",
        "    Return a preprocessed tokenized text.\n",
        "    \n",
        "    Args:\n",
        "        txt (str): original text to process\n",
        "        remove_stop (boolean): to remove or not stop words (common words)\n",
        "        do_stem (boolean): to do or not stemming (suffixes and prefixes removal)\n",
        "        to_lower (boolean): remove or not capital letters.\n",
        "        \n",
        "    Returns:\n",
        "        Return a preprocessed tokenized text.\n",
        "    \"\"\"      \n",
        "    if to_lower:\n",
        "        txt = txt.lower()\n",
        "    tokens = nltk.tokenize.word_tokenize(txt)\n",
        "    \n",
        "    if remove_stop:\n",
        "        tokens = [tk for tk in tokens if tk not in stop_words]\n",
        "    if do_stem:\n",
        "        tokens = [stemmer.stem(tk) for tk in tokens]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = list(doc_set.values())\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "tokenized_corpus_with_preprocessing = [preprocess_string(doc) for doc in corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluating Metric MRR@10 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.611111111111111"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Source: https://gist.github.com/bwhite/3726239\n",
        "def mean_reciprocal_rank(bool_results, k=10):\n",
        "    \"\"\"Score is reciprocal of the rank of the first relevant item\n",
        "    First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n",
        "    Example from http://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
        "    >>> rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
        "    >>> mean_reciprocal_rank(rs)\n",
        "    0.61111111111111105\n",
        "\n",
        "    Args:\n",
        "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "    Returns:\n",
        "        Mean reciprocal rank\n",
        "    \"\"\"\n",
        "    bool_results = (np.atleast_1d(r[:k]).nonzero()[0] for r in bool_results)\n",
        "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in bool_results])\n",
        "\n",
        "mean_reciprocal_rank([[0, 0, 1], [0, 1, 0], [1, 0, 0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def results_from_query(qry_id, bm25, pre_process=False):\n",
        "    \"\"\"Return an ordered array of relevant documents returned by query_id\n",
        "\n",
        "    Args:\n",
        "        qry_id (int): id of query on dataset\n",
        "        bm25 (object): indexed corpus\n",
        "\n",
        "    Returns:\n",
        "        boolean sorted relevance array of documents\n",
        "    \"\"\"    \n",
        "    query = qry_set[qry_id]\n",
        "    rel_docs = []\n",
        "    if qry_id in rel_set:\n",
        "        rel_docs = rel_set[qry_id]\n",
        "    if pre_process:\n",
        "        tokenized_query = preprocess_string(query)\n",
        "    else:\n",
        "        tokenized_query = query.split(\" \")\n",
        "    scores = bm25.get_scores(tokenized_query)\n",
        "    most_relevant_documents = np.argsort(-np.asarray(scores))\n",
        "    masked_relevance_results = np.zeros(most_relevant_documents.shape)\n",
        "  \n",
        "    masked_relevance_results[rel_docs] = 1\n",
        "    sorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n",
        "    \n",
        "    return sorted_masked_relevance_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcJExcHT10kk"
      },
      "source": [
        "# Simple BM25 implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w-oQmv6uyq3G"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "# Implementation from https://en.wikipedia.org/wiki/Okapi_BM25\n",
        "class BM25Simple(object):\n",
        "    PARAM_K1 = 1.2\n",
        "    PARAM_B = 0.75\n",
        "    EPSILON = 0.25\n",
        "\n",
        "    def __init__(self, corpus):\n",
        "        self.corpus_size = len(corpus)\n",
        "        self.dl = [float(len(d)) for d in corpus]\n",
        "        self.avgdl = sum(self.dl) / self.corpus_size\n",
        "        self.corpus = corpus\n",
        "        self.f = []\n",
        "        self.df = {}\n",
        "        self.idf = {}\n",
        "        self.average_idf = 0\n",
        "        self._initialize()\n",
        "\n",
        "    def _initialize(self):\n",
        "        for document in self.corpus:\n",
        "            frequencies = {}\n",
        "            for word in document:\n",
        "                if word not in frequencies:\n",
        "                    frequencies[word] = 0\n",
        "                frequencies[word] += 1\n",
        "            self.f.append(frequencies)\n",
        "\n",
        "            for word, freq in frequencies.items():\n",
        "                if word not in self.df:\n",
        "                    self.df[word] = 0\n",
        "                self.df[word] += 1\n",
        "\n",
        "        for word, freq in self.df.items():\n",
        "            self.idf[word] = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
        "\n",
        "        self.average_idf = sum(map(lambda k: float(self.idf[k]), self.idf.keys())) / len(self.idf.keys())\n",
        "\n",
        "    def _get_score(self, document, index):\n",
        "        score = 0\n",
        "        for word in document:\n",
        "            if word not in self.f[index]:\n",
        "                continue\n",
        "            idf = self.idf[word] if self.idf[word] >= 0 else self.EPSILON * self.average_idf\n",
        "            score += (idf * self.f[index][word] * (self.PARAM_K1 + 1)\n",
        "                      / (self.f[index][word] + self.PARAM_K1 * (1 - self.PARAM_B + self.PARAM_B * self.dl[index] / self.avgdl)))\n",
        "        return score\n",
        "\n",
        "    def _get_scores(self, document):\n",
        "        scores = []\n",
        "        for index in range(self.corpus_size):\n",
        "            score = self._get_score(document, index)\n",
        "            scores.append(score)\n",
        "        return scores\n",
        "\n",
        "    def get_scores(self, query, k=None):\n",
        "        \"\"\"Returns the `scores` of most relevant documents according to `query`\"\"\"\n",
        "        result = [(index, score) for index, score in enumerate(self._get_scores(query))]\n",
        "        result.sort(key=lambda x: x[1], reverse=True)\n",
        "        _, scores = zip(*result)\n",
        "        return scores\n",
        "    \n",
        "    def get_top_n(self, query, corpus, n=20):\n",
        "        \"\"\"Returns the `indexes` most relevant documents according to `query`\"\"\"\n",
        "        result = [(index, score) for index, score in enumerate(self._get_scores(query))]\n",
        "        result.sort(key=lambda x: x[1], reverse=True)\n",
        "        indexes, _ = zip(*result)\n",
        "        return [corpus[i] for i in indexes[:n]]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Indexing all documents from dataset with no preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Egzp-2CJ1tOB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "132.96301369863014\n"
          ]
        }
      ],
      "source": [
        "bm25_simple = BM25Simple(tokenized_corpus) # initialize bm25 model\n",
        "print(bm25_simple.avgdl)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select one query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "idx = random.sample(list(rel_set.keys()),1)[0]\n",
        "query = qry_set[idx] #get query text\n",
        "rel_docs = rel_set[idx] #get relevant documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How much do information retrieval and dissemination systems, as well as automated libraries, cost? Are they worth it to the researcher and to industry?\n",
            "[17, 26, 35, 48, 55, 58, 66, 73, 82, 125, 157, 163, 166, 191, 213, 221, 222, 249, 280, 291, 294, 298, 306, 330, 335, 337, 347, 364, 365, 366, 367, 371, 380, 445, 457, 464, 465, 481, 489, 490, 494, 496, 506, 519, 527, 590, 593, 622, 628, 638, 689, 719, 722, 723, 726, 727, 730, 778, 821, 833, 838, 847, 848, 864, 871, 896, 1099, 1160, 1247, 1304, 1352, 1357, 1362, 1365, 1367, 1370, 1371, 1373, 1374, 1375, 1376, 1409]\n"
          ]
        }
      ],
      "source": [
        "print(query)\n",
        "print(rel_docs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process query and get scores for each indexed document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(27.69059098299087, 26.089249721540284, 25.57380016889922, 25.324928895166078, 25.043902089468702, 24.18612909012977, 23.999872624571303, 23.860219369082273, 23.852044277609302, 23.69679134227739, 23.60121321726178, 23.499630788232857, 23.32750348503679, 23.256338826046168, 23.242008880343104, 23.147564214065753, 22.710861164464262, 22.651688787691786, 22.610927246354244, 22.4616504889854)\n"
          ]
        }
      ],
      "source": [
        "tokenized_query = query.split(\" \")\n",
        "most_relevant_documents = bm25_simple.get_scores(tokenized_query)\n",
        "print(most_relevant_documents[:20])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating single query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# create the boolean mask for the relevant documents to calculate MRR@10\n",
        "masked_relevance_results = np.zeros(len(most_relevant_documents))\n",
        "masked_relevance_results[rel_docs] = 1\n",
        "print(masked_relevance_results[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "sorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n",
        "print(sorted_masked_relevance_results[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5\n"
          ]
        }
      ],
      "source": [
        "# Calculate MRR@10 for document\n",
        "print(mean_reciprocal_rank([sorted_masked_relevance_results]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating all queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRR@10 0.0629\n"
          ]
        }
      ],
      "source": [
        "results = [results_from_query(qry_id, bm25_simple) for qry_id in list(qry_set.keys())]\n",
        "print(f'MRR@10 {mean_reciprocal_rank(results):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# file_name = \"models/BM25_simple.pkl\"\n",
        "# with open(file_name, 'wb') as file:\n",
        "#     pickle.dump(bm25_simple, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1460\n"
          ]
        }
      ],
      "source": [
        "# with open(file_name, 'rb') as file:\n",
        "#     model: BM25Simple = pickle.load(file)\n",
        "#     print(model.corpus_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRyKskdHXMHI"
      },
      "source": [
        "# BM25Okapi implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPsPjczNXTQ5",
        "outputId": "aeee25e2-a9e8-4706-9abf-188168981c6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from rank_bm25) (1.22.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install rank_bm25\n",
        "from rank_bm25 import BM25Okapi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGNpaaznYp3w"
      },
      "source": [
        "## Indexing all documents from dataset with no preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g05CWlmYjnW",
        "outputId": "b519db89-3db9-4772-efcf-72f852b2bbad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['18', 'Editions', 'of', 'the', 'Dewey', 'Decimal', 'Classifications', 'Comaromi,', 'J.P.', 'The', 'present', 'study', 'is', 'a', 'history', 'of', 'the', 'DEWEY', 'Decimal', 'Classification.', '', 'The', 'first', 'edition', 'of', 'the', 'DDC', 'was', 'published', 'in', '1876,', 'the', 'eighteenth', 'edition', 'in', '1971,', 'and', 'future', 'editions', 'will', 'continue', 'to', 'appear', 'as', 'needed.', '', 'In', 'spite', 'of', 'the', \"DDC's\", 'long', 'and', 'healthy', 'life,', 'however,', 'its', 'full', 'story', 'has', 'never', 'been', 'told.', '', 'There', 'have', 'been', 'biographies', 'of', 'Dewey', 'that', 'briefly', 'describe', 'his', 'system,', 'but', 'this', 'is', 'the', 'first', 'attempt', 'to', 'provide', 'a', 'detailed', 'history', 'of', 'the', 'work', 'that', 'more', 'than', 'any', 'other', 'has', 'spurred', 'the', 'growth', 'of', 'librarianship', 'in', 'this', 'country', 'and', 'abroad.', '']\n"
          ]
        }
      ],
      "source": [
        "# Index all documents using BM25\n",
        "print(tokenized_corpus[0])\n",
        "bm25 = BM25Okapi(tokenized_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN4cZGGwY8gg"
      },
      "source": [
        "## Select one query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0NZj3UmaY7Qo"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "idx = random.sample(list(rel_set.keys()),1)[0]\n",
        "query = qry_set[idx] #get query text\n",
        "rel_docs = rel_set[idx] #get relevant documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEypJd3fZcst"
      },
      "source": [
        "## Process query and get scores for each indexed document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Xx74IoZQDd",
        "outputId": "94de1932-de97-4654-da8f-fc6cd4765613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "query: How much do information retrieval and dissemination systems, as well as automated libraries, cost? Are they worth it to the researcher and to industry?\n",
            "Relevant documents IDs: [17, 26, 35, 48, 55, 58, 66, 73, 82, 125, 157, 163, 166, 191, 213, 221, 222, 249, 280, 291, 294, 298, 306, 330, 335, 337, 347, 364, 365, 366, 367, 371, 380, 445, 457, 464, 465, 481, 489, 490, 494, 496, 506, 519, 527, 590, 593, 622, 628, 638, 689, 719, 722, 723, 726, 727, 730, 778, 821, 833, 838, 847, 848, 864, 871, 896, 1099, 1160, 1247, 1304, 1352, 1357, 1362, 1365, 1367, 1370, 1371, 1373, 1374, 1375, 1376, 1409]\n",
            "[13.84492303 12.72656528 17.02184487 ... 12.72737224 14.26660278\n",
            " 14.10298505] 1460 1460\n"
          ]
        }
      ],
      "source": [
        "tokenized_query = query.split(\" \")\n",
        "print(f'query: {query}')\n",
        "print(f'Relevant documents IDs: {rel_docs}')\n",
        "\n",
        "scores = bm25.get_scores(tokenized_query)\n",
        "print(scores, len(scores), len(doc_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igfh-uPcavsj"
      },
      "source": [
        "## Evaluating single query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXy3iAY0ZtMc",
        "outputId": "e5d630d0-67cd-43ed-801a-f518334a193f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 655  593  254  663  767  176  292  514  363  139   23  313 1026  460\n",
            " 1447 1236  825  326 1276   27]\n"
          ]
        }
      ],
      "source": [
        "# argsort gives the indexes of values in increasing order, so we input with the negative values of scores\n",
        "most_relevant_documents = np.argsort(-scores)\n",
        "print(most_relevant_documents[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ibSQr6ccH55",
        "outputId": "32119c0c-a77b-4d46-c1ac-24f729684bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# create the boolean mask for the relevant documents to calculate MRR@10\n",
        "masked_relevance_results = np.zeros(most_relevant_documents.shape)\n",
        "masked_relevance_results[rel_docs] = 1\n",
        "print(masked_relevance_results[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYW5eZTbfdc9",
        "outputId": "67cd5f5b-0645-4591-d850-65881922a999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "sorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n",
        "print(sorted_masked_relevance_results[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51LWwEwJfipw",
        "outputId": "b2c77b1d-e85b-454f-e009-4eef7fde23b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5\n"
          ]
        }
      ],
      "source": [
        "# Calculate MRR@10 for document\n",
        "print(mean_reciprocal_rank([sorted_masked_relevance_results]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHPILaVniVQz"
      },
      "source": [
        "## Evaluating all queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpCPCXWqgQaj",
        "outputId": "584877aa-acda-4d64-eb2d-525a3b449c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRR@10 0.3146\n"
          ]
        }
      ],
      "source": [
        "results = [results_from_query(qry_id, bm25) for qry_id in list(qry_set.keys())]\n",
        "print(f'MRR@10 {mean_reciprocal_rank(results):.4f}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "FB2ozkpAinED"
      },
      "outputs": [],
      "source": [
        "# file_name = \"models/BM25Okapi.pkl\"\n",
        "# with open(file_name, 'wb') as file:\n",
        "#     pickle.dump(bm25, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1460\n"
          ]
        }
      ],
      "source": [
        "# with open(file_name, 'rb') as file:\n",
        "#     model: BM25Okapi = pickle.load(file)\n",
        "#     print(model.corpus_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BM25+ implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages (from rank_bm25) (1.22.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install rank_bm25\n",
        "from rank_bm25 import BM25Plus"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Indexing all documents from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['18', 'Editions', 'of', 'the', 'Dewey', 'Decimal', 'Classifications', 'Comaromi,', 'J.P.', 'The', 'present', 'study', 'is', 'a', 'history', 'of', 'the', 'DEWEY', 'Decimal', 'Classification.', '', 'The', 'first', 'edition', 'of', 'the', 'DDC', 'was', 'published', 'in', '1876,', 'the', 'eighteenth', 'edition', 'in', '1971,', 'and', 'future', 'editions', 'will', 'continue', 'to', 'appear', 'as', 'needed.', '', 'In', 'spite', 'of', 'the', \"DDC's\", 'long', 'and', 'healthy', 'life,', 'however,', 'its', 'full', 'story', 'has', 'never', 'been', 'told.', '', 'There', 'have', 'been', 'biographies', 'of', 'Dewey', 'that', 'briefly', 'describe', 'his', 'system,', 'but', 'this', 'is', 'the', 'first', 'attempt', 'to', 'provide', 'a', 'detailed', 'history', 'of', 'the', 'work', 'that', 'more', 'than', 'any', 'other', 'has', 'spurred', 'the', 'growth', 'of', 'librarianship', 'in', 'this', 'country', 'and', 'abroad.', '']\n"
          ]
        }
      ],
      "source": [
        "# Index all documents using BM25\n",
        "corpus = list(doc_set.values())\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "print(tokenized_corpus[0])\n",
        "bm25_plus = BM25Plus(tokenized_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select one query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "idx = random.sample(list(rel_set.keys()),1)[0]\n",
        "query = qry_set[idx] #get query text\n",
        "rel_docs = rel_set[idx] #get relevant documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process query and get scores for each indexed document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "query: How much do information retrieval and dissemination systems, as well as automated libraries, cost? Are they worth it to the researcher and to industry?\n",
            "Relevant documents IDs: [17, 26, 35, 48, 55, 58, 66, 73, 82, 125, 157, 163, 166, 191, 213, 221, 222, 249, 280, 291, 294, 298, 306, 330, 335, 337, 347, 364, 365, 366, 367, 371, 380, 445, 457, 464, 465, 481, 489, 490, 494, 496, 506, 519, 527, 590, 593, 622, 628, 638, 689, 719, 722, 723, 726, 727, 730, 778, 821, 833, 838, 847, 848, 864, 871, 896, 1099, 1160, 1247, 1304, 1352, 1357, 1362, 1365, 1367, 1370, 1371, 1373, 1374, 1375, 1376, 1409]\n",
            "[13.84492303 12.72656528 17.02184487 ... 12.72737224 14.26660278\n",
            " 14.10298505] 1460 1460\n"
          ]
        }
      ],
      "source": [
        "tokenized_query = query.split(\" \")\n",
        "print(f'query: {query}')\n",
        "print(f'Relevant documents IDs: {rel_docs}')\n",
        "\n",
        "scores = bm25.get_scores(tokenized_query)\n",
        "print(scores, len(scores), len(doc_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating single query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 655  593  254  663  767  176  292  514  363  139   23  313 1026  460\n",
            " 1447 1236  825  326 1276   27]\n"
          ]
        }
      ],
      "source": [
        "# argsort gives the indexes of values in increasing order, so we input with the negative values of scores\n",
        "most_relevant_documents = np.argsort(-scores)\n",
        "print(most_relevant_documents[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# create the boolean mask for the relevant documents to calculate MRR@10\n",
        "masked_relevance_results = np.zeros(most_relevant_documents.shape)\n",
        "masked_relevance_results[rel_docs] = 1\n",
        "print(masked_relevance_results[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "sorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n",
        "print(sorted_masked_relevance_results[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5\n"
          ]
        }
      ],
      "source": [
        "# Calculate MRR@10 for document\n",
        "print(mean_reciprocal_rank([sorted_masked_relevance_results]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating all queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRR@10 0.3334\n"
          ]
        }
      ],
      "source": [
        "results = [results_from_query(qry_id, bm25_plus) for qry_id in list(qry_set.keys())]\n",
        "print(f'MRR@10 {mean_reciprocal_rank(results):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# file_name = \"models/BM25Plus.pkl\"\n",
        "# with open(file_name, 'wb') as file:\n",
        "#     pickle.dump(bm25, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1460\n"
          ]
        }
      ],
      "source": [
        "# with open(file_name, 'rb') as file:\n",
        "#     model: BM25Plus = pickle.load(file)\n",
        "#     print(model.corpus_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation with preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BM25Simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRR@10 0.0629\n"
          ]
        }
      ],
      "source": [
        "results = [results_from_query(qry_id, bm25_simple, pre_process=True) for qry_id in list(qry_set.keys())]\n",
        "print(f'MRR@10 {mean_reciprocal_rank(results):.4f}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BM25OKapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRR@10 0.1475\n"
          ]
        }
      ],
      "source": [
        "results = [results_from_query(qry_id, bm25, pre_process=True) for qry_id in list(qry_set.keys())]\n",
        "print(f'MRR@10 {mean_reciprocal_rank(results):.4f}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BM25+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRR@10 0.1487\n"
          ]
        }
      ],
      "source": [
        "results = [results_from_query(qry_id, bm25_plus, pre_process=True) for qry_id in list(qry_set.keys())]\n",
        "print(f'MRR@10 {mean_reciprocal_rank(results):.4f}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "numpy==1.22.1\n",
            "pandas==1.4.3\n",
            "nltk==3.8.1\n"
          ]
        }
      ],
      "source": [
        "print('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "c11202d2846b22eec7deaf37ea813ba92a5f75b5344a4d16688175855af7948e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
